<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>OREPA on Louaq</title><link>https://toupyo.github.io/tags/orepa/</link><description>Recent content in OREPA on Louaq</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>© 2024 Louaq</copyright><lastBuildDate>Fri, 04 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://toupyo.github.io/tags/orepa/index.xml" rel="self" type="application/rss+xml"/><item><title>OREPA</title><link>https://toupyo.github.io/docs/ai/</link><pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate><guid>https://toupyo.github.io/docs/ai/</guid><description>&lt;h2 class="relative group">一、本文介绍
&lt;div id="%E4%B8%80%E6%9C%AC%E6%96%87%E4%BB%8B%E7%BB%8D" class="anchor">&lt;/div>
&lt;/h2>
&lt;p>本文给大家带来的改进机制是一种重参数化的卷积模块&lt;strong>OREPA&lt;/strong>，这种重参数化模块非常适合用于二次创新，我们可以将其替换网络中的其它卷积模块可以不影响推理速度的同时让模型学习到更多的特征。&lt;strong>OREPA&lt;/strong>是通过&lt;strong>在线卷积重参数化（Online Convolutional Re-parameterization）&lt;strong>来减少深度学习模型训练的成本和复杂性。这种方法主要包括&lt;/strong>两个阶段&lt;/strong>：首先，利用一个特殊的线性缩放层来优化在线块的性能；其次，通过将复杂的训练时模块压缩成一个单一的卷积来减少训练开销。&lt;/p></description><media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://toupyo.github.io/docs/ai/featured.png"/></item></channel></rss>